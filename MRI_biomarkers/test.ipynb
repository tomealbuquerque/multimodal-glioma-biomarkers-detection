{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "import torchio\n",
    "from torchio.transforms import (\n",
    "    RescaleIntensity,\n",
    "    Compose,\n",
    ")\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "class R2Plus1dStem4MRI(nn.Sequential):\n",
    "    \"\"\"R(2+1)D stem is different than the default one as it uses separated 3D convolution\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(R2Plus1dStem4MRI, self).__init__(\n",
    "            nn.Conv3d(1, 155, kernel_size=(1, 7, 7),\n",
    "                      stride=(1, 2, 2), padding=(0, 3, 3),\n",
    "                      bias=False),\n",
    "            nn.BatchNorm3d(155),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv3d(155, 64, kernel_size=(3, 1, 1),\n",
    "                      stride=(1, 1, 1), padding=(1, 0, 0),\n",
    "                      bias=False),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "class MRIDatasets:\n",
    "    def __init__(self, dataset_path, metadata_path):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.metadata = metadata_path\n",
    "\n",
    "    def tcga(self):\n",
    "        metadata_df = pd.read_csv(self.metadata)\n",
    "\n",
    "        imgs = []\n",
    "        for path, currentDir, files in os.walk(self.dataset_path):\n",
    "            for file in files:\n",
    "                if file.endswith('t1ce.nii.gz'):\n",
    "                    subject_id = os.path.basename(path)\n",
    "                    img_path = Path(path + os.sep + 't1ce.nii.gz')\n",
    "                    row_df = metadata_df[metadata_df['subject_id'] == subject_id]\n",
    "                    # there might be more than one row found in csv file\n",
    "                    label = int(row_df['IDH1_mut'].unique()[0] + row_df['loh1p/19q_cnv'].unique()[0])\n",
    "                    imgs.append(torchio.Subject(t1=torchio.ScalarImage(img_path), label=label,))\n",
    "\n",
    "        return imgs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "total_samples = MRIDatasets(dataset_path='../data_multimodal_tcga/Radiology', metadata_path='../data_multimodal_tcga/patient-info-tcga.csv').tcga()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "total_samples = total_samples[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# for dataset being unbalanced for classes [0, 1, 2]\n",
    "class_weights = torch.FloatTensor([1, 2.2, 4.1])\n",
    "\n",
    "# Transforms\n",
    "rescale = RescaleIntensity((0.05, 99.5))\n",
    "randaffine = torchio.RandomAffine(scales=(0.9,1.2),degrees=10, isotropic=True, image_interpolation='nearest')\n",
    "flip = torchio.RandomFlip(axes=('LR'), p=0.5)\n",
    "transforms = [rescale, flip, randaffine]\n",
    "\n",
    "transform = Compose(transforms)\n",
    "\n",
    "subjects_dataset = torchio.SubjectsDataset(total_samples, transform=transform)\n",
    "\n",
    "# train/test split\n",
    "train_set_samples = (int(len(total_samples) - 0.2 * len(total_samples)))\n",
    "test_set_samples = (int(len(total_samples)) - (train_set_samples))\n",
    "\n",
    "trainset, testset = torch.utils.data.random_split(subjects_dataset, [train_set_samples, test_set_samples],\n",
    "                                                  generator=torch.Generator().manual_seed(55))\n",
    "\n",
    "trainloader = DataLoader(dataset=trainset, batch_size=1, shuffle=True, num_workers=1)\n",
    "testloader = DataLoader(dataset=testset, batch_size=1, shuffle=True, num_workers=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VideoResNet(\n",
      "  (stem): R2Plus1dStem4MRI(\n",
      "    (0): Conv3d(1, 155, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
      "    (1): BatchNorm3d(155, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv3d(155, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "    (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2Plus1D(\n",
      "          (0): Conv3d(64, 144, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv3d(144, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        )\n",
      "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2Plus1D(\n",
      "          (0): Conv3d(64, 144, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv3d(144, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        )\n",
      "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2Plus1D(\n",
      "          (0): Conv3d(64, 144, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv3d(144, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        )\n",
      "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2Plus1D(\n",
      "          (0): Conv3d(64, 144, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv3d(144, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        )\n",
      "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2Plus1D(\n",
      "          (0): Conv3d(64, 230, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv3d(230, 128, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        )\n",
      "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2Plus1D(\n",
      "          (0): Conv3d(128, 230, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv3d(230, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        )\n",
      "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2Plus1D(\n",
      "          (0): Conv3d(128, 288, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv3d(288, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        )\n",
      "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2Plus1D(\n",
      "          (0): Conv3d(128, 288, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv3d(288, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        )\n",
      "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2Plus1D(\n",
      "          (0): Conv3d(128, 460, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(460, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv3d(460, 256, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        )\n",
      "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2Plus1D(\n",
      "          (0): Conv3d(256, 460, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(460, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv3d(460, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        )\n",
      "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2Plus1D(\n",
      "          (0): Conv3d(256, 576, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv3d(576, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        )\n",
      "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2Plus1D(\n",
      "          (0): Conv3d(256, 576, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv3d(576, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        )\n",
      "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2Plus1D(\n",
      "          (0): Conv3d(256, 921, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(921, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv3d(921, 512, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        )\n",
      "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2Plus1D(\n",
      "          (0): Conv3d(512, 921, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(921, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv3d(921, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        )\n",
      "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2Plus1D(\n",
      "          (0): Conv3d(512, 1152, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv3d(1152, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        )\n",
      "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2Plus1D(\n",
      "          (0): Conv3d(512, 1152, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv3d(1152, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        )\n",
      "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=512, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.video.r2plus1d_18(pretrained=False)\n",
    "model.stem = R2Plus1dStem4MRI()\n",
    "\n",
    "# regularization\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(model.fc.in_features, 3)\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "\n",
    "# Initialize the prediction and label lists(tensors) for confusion matrix\n",
    "predlist = torch.zeros(0, dtype=torch.long).to(device)\n",
    "lbllist = torch.zeros(0, dtype=torch.long).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [1/149], Loss: 0.5056, Accuracy: 100.00%\n",
      "Test Accuracy of the model: 23.68421052631579 %\n",
      "Epoch [1/2], Step [2/149], Loss: 1.5871, Accuracy: 50.00%\n",
      "Test Accuracy of the model: 31.57894736842105 %\n",
      "Epoch [1/2], Step [3/149], Loss: 1.7863, Accuracy: 33.33%\n",
      "Test Accuracy of the model: 26.31578947368421 %\n",
      "Epoch [1/2], Step [4/149], Loss: 2.0876, Accuracy: 25.00%\n",
      "Test Accuracy of the model: 26.31578947368421 %\n",
      "Epoch [1/2], Step [5/149], Loss: 1.8404, Accuracy: 40.00%\n",
      "Test Accuracy of the model: 26.31578947368421 %\n",
      "Epoch [1/2], Step [6/149], Loss: 1.9646, Accuracy: 33.33%\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "epochs = 2\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    logs = {}\n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    total_images = 0\n",
    "    total_val_loss = 0\n",
    "\n",
    "    for i, traindata in enumerate(trainloader):\n",
    "        images = F.interpolate(traindata['t1'][torchio.DATA], scale_factor=(0.7, 0.7, 0.7)).to(device)\n",
    "        labels = traindata['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward propagation\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward prop\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating gradients\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "\n",
    "        # Total number of labels\n",
    "        total_images += labels.size(0)\n",
    "\n",
    "        # Obtaining predictions from max value\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Calculate the number of correct answers\n",
    "        correct = (predicted == labels).sum().item()\n",
    "\n",
    "        total_correct += correct\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        running_trainacc = ((total_correct / total_images) * 100)\n",
    "\n",
    "        logs['log loss'] = total_loss / total_images\n",
    "        logs['Accuracy'] = ((total_correct / total_images) * 100)\n",
    "\n",
    "        print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "              .format(epoch + 1, epochs, i + 1, len(trainloader), (total_loss / total_images),\n",
    "                      (total_correct / total_images) * 100))\n",
    "\n",
    "        # Testing the model\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for testdata in testloader:\n",
    "                images = F.interpolate(testdata['t1'][torchio.DATA], scale_factor=(0.7, 0.7, 0.7)).to(device)\n",
    "\n",
    "                labels = testdata['label'].to(device)\n",
    "                outputs = model(images)\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                predlist = torch.cat([predlist, predicted.view(-1)])  # Append batch prediction results\n",
    "\n",
    "                lbllist = torch.cat([lbllist, labels.view(-1)])\n",
    "\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                total_losss = loss.item()\n",
    "\n",
    "                accuracy = correct / total\n",
    "\n",
    "            print('Test Accuracy of the model: {} %'.format(100 * correct / total))\n",
    "\n",
    "            logs['val_' + 'log loss'] = total_loss / total\n",
    "            validationloss = total_loss / total\n",
    "\n",
    "            validationacc = ((correct / total) * 100)\n",
    "            logs['val_' + 'Accuracy'] = ((correct / total) * 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(lbllist.cpu().numpy(), predlist.cpu().numpy())\n",
    "\n",
    "print(conf_mat)\n",
    "cls = [\"0\", \"1\", \"2\"]\n",
    "# Per-class accuracy\n",
    "class_accuracy = 100 * conf_mat.diagonal() / conf_mat.sum(1)\n",
    "print(class_accuracy)\n",
    "plt.figure(figsize=(10, 10))\n",
    "# plot_confusion_matrix(conf_mat, cls)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}